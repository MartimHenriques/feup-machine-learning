{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"67872a012bdb43f592d2523ec60270e0","deepnote_cell_type":"markdown"},"source":["# Data Mining Project\n","\n","## Knowledge Extraction Pipeline\n","\n","This notebooks defines a series of steps that end up in the production of the desired prediction, including Data Preparation, Modeling and Evaluation, according to CRISP-DM guidelines.\n","For information regarding Data Understanding, please refer to [Data Understanding](data_understanding.ipynb).\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Dependencies\n","\n","The code block below defines the major dependencies for the project.\n","To make sure you are set up, please run the following command in order to update dependencies:\n","\n","```bash\n","pip install -r requirements.txt\n","```\n","\n","We chose to use a set of technologies that we were familiar with and should be adequate for the problem at hand.\n","These include **sklearn** to model the data, **matplotlib** and **seaborn** to create graphics and **pandas** to better read the data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6e851747f14941a7b10f7b4d9dfd1023","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2933,"execution_start":1696271818178,"source_hash":null},"outputs":[],"source":["# Dependencies\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","from utils.files import *"]},{"cell_type":"markdown","metadata":{},"source":["## Data Understanding\n","\n","### Related Work\n","\n","Sports related predictions are a fairly common problem.\n","It serves of value for different entities, such as bookmakers, sports teams and fans.\n","This fact together with the recent increase in the availability of data justifies the employment of machine learning techniques to the problem. [<a href=\"#ref1\">1</a>]\n","\n","The problem of predicting the outcome of a basketball game has been approached in different ways.\n","A common take on the subject is to try and predict the outcome of a single game, as opposed to the set of qualified teams.\n","Nevertheless, some similarities found between solutions were the use of machine learning algorithms and of similar attributes (rebounds, free throws, turn overs, etc).\n","\n","In [<a href=\"#ref2\">2</a>] the authors identify the characteristic high-dimensionality of the problem, and employ a Support Vector Machine Algorithm that predicted the outcome of a game with 88% accuracy.\n","\n","Among common attributes, the author of [<a href=\"#ref3\">3</a>] found that the most important ones were Free Throws, Offensive Rebounds, Turn Overs and +/- (Plus Minus).\n","They were also able to predict the champion team with an 86% recall using Random Forest.\n","\n","Finally, the authors of [<a href=\"#ref4\">4</a>] used a Naive Bayes Classifier to predict the outcome of games with 67% accuracy.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation\n","\n","TODO: add text about data set (summary from data exploration)\n"]},{"cell_type":"markdown","metadata":{},"source":["TODO: add text about which transformations were made\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(os.path.join(DATA_PATH, DATA_MERGED))\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling and Evaluation\n","\n","The following block imports general utility functions (defined in `utils/modeling.py`) that will serve to model the data and access results.\n","\n","We chose to create the training and testing subsets in a temporal fashion.\n","The reason being it wouldn't make sense to scatter data from different years, since our game data is chronological.\n","As an example, we can train the model with the first 9 years and use the 10th and last to test the model's predictions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"27a37643231b45e9a939fcf23e3b309f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":878,"execution_start":1696271821786,"source_hash":null},"outputs":[],"source":["from utils.modeling import *\n"]},{"cell_type":"markdown","metadata":{},"source":["### Ranking-based prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pred():\n","    # check if df has keys confID per, eff. if not, return\n","    if not {'confID', 'per', 'eff'}.issubset(df.columns):\n","        return\n","    \n","    test_year = 10\n","    test_df = df[df['year'] == test_year]\n","\n","    X_test = test_df.drop(columns=['playoff'])\n","    y_test = test_df['playoff']\n","\n","    criteria = 'eff'\n","    threshold = { \n","        'EA' : X_test[X_test['confID'] == 'EA'][criteria].nlargest(4).min(),\n","        'WE' : X_test[X_test['confID'] == 'WE'][criteria].nlargest(4).min()\n","        }\n","    y_pred = X_test.apply(lambda row: 1 if row[criteria] >= threshold[row['confID']] else 0, axis=1)\n","    X_test['playoff'] = y_test\n","    X_test['pred'] = y_pred\n","    X_test['Correct'] = X_test.apply(lambda row: True if row['pred'] == row['playoff'] else False, axis=1)\n","\n","    print(threshold)\n","    display(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    displayResults(Result(y_test, y_pred, accuracy, precision, recall, f1))\n","\n","pred()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from utils.modeling import *"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"50e3b327a67342308fc859c50b48696f","deepnote_cell_type":"code"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import svm\n","\n","models = {\n","    \"Decision Tree\" : DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_leaf=8, min_samples_split=3),\n","    \"Random Forest\" : RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42),\n","    \"Naive Bayes\" : GaussianNB(),\n","    \"Neural Net\" : MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=42, max_iter=500),\n","    \"SVM\" : svm.SVC(kernel='linear', C=1, random_state=42)\n","    }\n","\n","# very best hyperparametrs\n","\n","models = {\n","    \"Decision Tree\" : DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_leaf=8, min_samples_split=3),\n","    \"Random Forest\" : RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42),\n","    \"Naive Bayes\" : GaussianNB(),\n","    \"Neural Net\" : MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=42, max_iter=500),\n","    \"SVM\" : svm.SVC(kernel='linear', C=1, random_state=42)\n","    }\n","\n","\n","def testDf(test_year, models, display_results=True):\n","    print(\"Testing on year\", test_year)\n","    results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n","    for name, model in models.items():\n","        res = runModel(df, model, test_year=test_year)\n","        results.loc[len(results)] = [name] + res.toRow()\n","    \n","    #make an average row\n","    results.loc[len(results)] = [\"Average\"] + results.mean(axis=0, numeric_only=True).tolist()\n","\n","    if display_results: display(results)\n","    return results\n","\n","avg_score = pd.DataFrame(columns=['year', 'Accuracy', 'Precision', 'Recall', 'F1'])\n","\n","for i in range(4, 11):\n","    r = testDf(i,models,display_results=True)\n","    avg_score.loc[len(avg_score)] = [str(i)] +(r.iloc[-1]).tolist()[1:]\n","\n","avg_score.loc[len(avg_score)] = [\"Average\"] + avg_score.mean(axis=0, numeric_only=True).tolist()\n","display(avg_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import ensemble as ens\n","\n","models_dict = {}\n","\n","# Voting with all models\n","# models_dict['ensemble hard'] = ens.VotingClassifier(estimators=list(models.items()), voting='hard')\n","\n","# Voting just for Decision Tree and Random Forest\n","models_new={\n","    \"Decision Tree\" : DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_leaf=8, min_samples_split=3),\n","    \"Random Forest\" : RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n","} \n","models_dict['ensemble hard'] = ens.VotingClassifier(estimators=list(models_new.items()), voting='hard')\n","\n","ensemble_score = pd.DataFrame(columns=['year', 'Accuracy', 'Precision', 'Recall', 'F1'])\n","\n","for i in range(4, 11):\n","    r = testDf(i,models_dict,display_results=True)\n","    ensemble_score.loc[len(ensemble_score)] = [str(i)] + (r.iloc[-1]).tolist()[1:]\n","\n","ensemble_score.loc[len(ensemble_score)] = [\"Average\"] + ensemble_score.mean(axis=0, numeric_only=True).tolist()\n","display(ensemble_score)"]},{"cell_type":"markdown","metadata":{},"source":["### References\n","\n","<a id=\"ref1\"></a> [1] Bunker, R. P., & Thabtah, F. (2019). A machine learning framework for sport result prediction. Applied Computing and Informatics, 15(1), 27-33. https://doi.org/10.1016/j.aci.2017.09.005\n","\n","<a id=\"ref2\"></a> [2] Jadhav, A. (2016). Predicting the NBA playoff using SVM. CORE. https://core.ac.uk/display/230494997?utm_source=pdf&utm_medium=banner&utm_campaign=pdf-decoration-v1\n","\n","<a id=\"ref3\"></a> [3] Jien, O. W. (2022, January 5). Prediction model for NBA championship by Machine Learning. Medium. https://medium.com/@weinjien99/prediction-model-for-nba-championship-by-machine-learning-8e8884ea72c8\n","\n","<a id=\"ref4\"></a> [4] D. Miljković, L. Gajić, A. Kovačević and Z. Konjović, \"The use of data mining for basketball matches outcomes prediction,\" IEEE 8th International Symposium on Intelligent Systems and Informatics, Subotica, Serbia, 2010, pp. 309-312, doi: 10.1109/SISY.2010.5647440.\n"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"6e492a3567604459952befba0607df26","deepnote_persisted_session":{"createdAt":"2023-10-02T19:01:36.460Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
